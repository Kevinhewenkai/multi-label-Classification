{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from io import StringIO\n",
    "import os\n",
    "from PIL import Image\n",
    "import csv\n",
    "from transformers import ViTModel, ViTFeatureExtractor, BertTokenizer, BertModel\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMAGE_PATH = './dataset/data/'\n",
    "TRAINING_DATA_PATH = './dataset/train.csv'\n",
    "TEST_DATA_PATH = './dataset/test.csv'\n",
    "LABEL_COUNT = 19\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SHAPE = 224\n",
    "LR = 0.0001\n",
    "EPOCHS = 1\n",
    "WEIGHT_DECAY = 0.001\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using', device)\n",
    "# Feature Extractor for ViT\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(\"Initialise vit and bert\")\n",
    "\n",
    "# Reading CSV Files (unchanged)\n",
    "def read_csv(file_path):\n",
    "    with open(file_path) as file:\n",
    "        lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
    "        df = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
    "    return df\n",
    "\n",
    "df_train = read_csv(TRAINING_DATA_PATH)\n",
    "df_test = read_csv(TEST_DATA_PATH)\n",
    "\n",
    "# Dataset Class (modified for ViT)\n",
    "class ImageTextDataset(Dataset):\n",
    "    def __init__(self, df, image_path, processor, tokenizer, max_length=128, test=False):\n",
    "        self.df = df\n",
    "        self.image_path = image_path\n",
    "        self.processor = processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = os.path.join(self.image_path, row['ImageID'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        image = self.processor(images=image, return_tensors=\"pt\")['pixel_values'].squeeze(0)\n",
    "        \n",
    "        caption = row['Caption']\n",
    "        inputs = self.tokenizer(caption, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        input_ids = inputs['input_ids'].squeeze(0)\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
    "        \n",
    "        if self.test :\n",
    "            return image, input_ids, attention_mask\n",
    "\n",
    "\n",
    "        labels = torch.zeros(LABEL_COUNT, dtype=torch.float32)\n",
    "        label_indices = [int(l) for l in row['Labels'].split()]\n",
    "        for label_index in label_indices:\n",
    "            if label_index > 0 and label_index <= LABEL_COUNT:  # Check to ensure index is within the valid range\n",
    "                labels[label_index - 1] = 1  # Correct indexing for Python (0-based)\n",
    "\n",
    "        return image, input_ids, attention_mask, labels\n",
    "\n",
    "\n",
    "# Datasets and DataLoaders (slightly adjusted)\n",
    "train_dataset = ImageTextDataset(df_train, IMAGE_PATH, feature_extractor, tokenizer)\n",
    "test_dataset = ImageTextDataset(df_test, IMAGE_PATH, feature_extractor, tokenizer, test=True)\n",
    "\n",
    "# Splitting Dataset (unchanged)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Small Model ï¼Œ you can try\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        combined_dim = self.vit.config.hidden_size + self.bert.config.hidden_size\n",
    "        self.classifier = nn.Linear(combined_dim, num_classes)\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        image_features = self.vit(pixel_values=images).pooler_output\n",
    "        text_features = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
    "        logits = self.classifier(combined_features)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = CombinedModel(num_classes=LABEL_COUNT).to(device)\n",
    "torch.save(model.state_dict(), './model')\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(total=len(train_loader), desc='Training', leave=False)\n",
    "    for images, input_ids, attention_mask, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "    scheduler.step()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for images, input_ids, attention_mask, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    pred_labels = (all_preds > THRESHOLD).astype(int)\n",
    "    \n",
    "    f1 = f1_score(all_targets, pred_labels, average='micro')\n",
    "    accuracy = accuracy_score(all_targets, pred_labels)\n",
    "    recall = recall_score(all_targets, pred_labels, average='micro')\n",
    "    return running_loss / len(val_loader.dataset), f1, accuracy, recall\n",
    "\n",
    "print(\"Start training\")\n",
    "# Main training loop with progress bar\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, scheduler)\n",
    "    val_loss, val_f1, val_acc, val_recall = validate(model, val_loader, criterion)\n",
    "    tqdm.write(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, F1 Score: {val_f1:.4f}, Acc Score \\\n",
    "       : {val_acc}, Recall Score :{val_recall}')\n",
    "\n",
    "print(\"End training\")\n",
    "\n",
    "# Testing Function\n",
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, input_ids, attention_mask in test_loader:\n",
    "            images = images.to(device)\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            preds = torch.sigmoid(outputs).cpu().detach().numpy()\n",
    "            binary_preds = (preds > THRESHOLD).astype(int)\n",
    "            labels = [' '.join([str(i+1) for i, val in enumerate(pred) if val == 1]) for pred in binary_preds]\n",
    "            predictions.extend(labels)\n",
    "    return predictions\n",
    "\n",
    "print(\"start prediction\")\n",
    "# Output Predictions\n",
    "predictions = predict(model, test_loader)\n",
    "\n",
    "# Export Predictions\n",
    "output_file = 'predictions.csv'\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ImageID', 'Labels'])\n",
    "    for idx, img_id in enumerate(df_test['ImageID']):\n",
    "        writer.writerow([img_id, predictions[idx]])\n",
    "\n",
    "print(f'Predictions exported to {output_file}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
